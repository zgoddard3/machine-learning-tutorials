{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e088a871",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "This tutorial will walk through some initial concepts and algorithms for reinforcement learning (RL). I'll assume you've already done the general introduction on supervised learning with Tensorflow. We'll start with basic Q-learning to introduce the concept of RL, but you will need to be familiar with Tensorflow models for some of the later algorithms.\n",
    "\n",
    "Additionally, the focus of this tutorial will be on RL in control applications. We'll start by introducing the cartpole problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48f0e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import time\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22390a12",
   "metadata": {},
   "source": [
    "## Loading Gym Environments\n",
    "\n",
    "OpenAI's Gym has a range of environments designed for RL experiments load in and use out-of-the-box. These environments include a simple cartpole problem. This environment gives the position and velocity of the cart and the angle and angular rate of the pendulum as the observation. There are two possible actions for the agent: push left or push right. The agent receives a reward of +1 every time step until the cart position or pendulum angle pass a given threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0ea1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "Action: Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "print(\"Observation:\", env.observation_space)\n",
    "print(\"Action:\", env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119804db",
   "metadata": {},
   "source": [
    "We can quickly visualize this environment to see how an agent is performing. Since we don't yet have an agent, we'll just sample actions randomly. Of course, this policy won't last long before failing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e78bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    _, _, done, _ = env.step(action)\n",
    "    img.set_data(env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300118de",
   "metadata": {},
   "source": [
    "## Q-Learning\n",
    "\n",
    "We start by solving this algorithm with Q-learning. This isn't a *Deep* RL algorithm, but it provides a more clear example of the principles that later algorithms will be working off of. \n",
    "\n",
    "The objective of Q-Learning (and many algorithms we explore later) is to learn a function to predict the value for taking an action at a given state. In mathematical terms, $Q : S \\times A \\rightarrow \\mathbb{R}$ where $S$ is the state space $A$ is the action space. \n",
    "\n",
    "Regular Q-Learning represents this function as a look-up table and learns each value through dynamic programming. Experience is sampled from the environment in the for $(s_t, a_t, s_{t+1})$. Each time new experience is sampled, the Q value is updated by the equation:\n",
    "\n",
    "$Q_{i+1}(s_t, a_t) \\leftarrow R(s_t, a_t, s_{t+1}) + \\gamma \\max_a Q_i(s_{t+1}, a)$\n",
    "\n",
    "This is the sum of the immediate rewards, $R(s_t, a_t, s_{t+1})$, and the future rewards estimated by the Q function discounted by some $\\gamma$ between 0 and 1. \n",
    "\n",
    "Since the state space of the cartpole is continuous, we need to discretize it before we can build a Q table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b420b263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [-6 -4 -2  0  2  4]\n",
      "theta: [-0.42 -0.21  0.    0.21]\n",
      "thetadot: [ -inf -0.1  -0.05  0.    0.05  0.1 ]\n",
      "xdot: [-inf -1.  -0.5  0.   0.5  1. ]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(-6, 5, 2)\n",
    "xdot = np.array([-np.inf, -1, -.5, 0, .5, 1])\n",
    "theta = np.arange(-0.42, .42, .21)\n",
    "thetadot = np.array([-np.inf, -.1, -.05, 0, .05, .1])\n",
    "\n",
    "print(\"x:\", x)\n",
    "print(\"theta:\", theta)\n",
    "print(\"thetadot:\", thetadot)\n",
    "print(\"xdot:\", xdot)\n",
    "\n",
    "N = x.shape[0]*xdot.shape[0]*theta.shape[0]*thetadot.shape[0]\n",
    "\n",
    "Q = np.zeros((N,2))\n",
    "\n",
    "def q_map(obs):\n",
    "    i = np.nonzero(x <= obs[0])[0][-1]\n",
    "    j = np.nonzero(xdot <= obs[1])[0][-1]\n",
    "    k = np.nonzero(theta <= obs[2])[0][-1]\n",
    "    l = np.nonzero(thetadot <= obs[3])[0][-1]\n",
    "    \n",
    "    return l + (k + (j + i*xdot.shape[0])*theta.shape[0])*thetadot.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f8e1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "6\n",
      "24\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "print(q_map(np.array([-4.5, -2, -.4, -.2])))\n",
    "print(q_map(np.array([-4.5, -2, -.4, -.08])))\n",
    "print(q_map(np.array([-4.5, -2, -.1, -.2])))\n",
    "print(q_map(np.array([-4.5, -.8, -.4, -.2])))\n",
    "print(q_map(np.array([-2.5, -2, -.4, -.2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c4dfc",
   "metadata": {},
   "source": [
    "Now we just need to collect some experience and update our Q function until it converges on a successful policy. Feel free to run the following cell a few times until the total return is at a satisfactory value. (Note this probably won't acheive a particularly high score. Just train it until it can reach a score of 100 every once in a while)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38c3eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\n",
      "Total return: 27.0\n",
      "Episode 1\n",
      "Total return: 13.0\n",
      "Episode 2\n",
      "Total return: 37.0\n",
      "Episode 3\n",
      "Total return: 47.0\n",
      "Episode 4\n",
      "Total return: 18.0\n",
      "Episode 5\n",
      "Total return: 31.0\n",
      "Episode 6\n",
      "Total return: 16.0\n",
      "Episode 7\n",
      "Total return: 81.0\n",
      "Episode 8\n",
      "Total return: 24.0\n",
      "Episode 9\n",
      "Total return: 32.0\n",
      "Episode 10\n",
      "Total return: 32.0\n",
      "Episode 11\n",
      "Total return: 46.0\n",
      "Episode 12\n",
      "Total return: 26.0\n",
      "Episode 13\n",
      "Total return: 30.0\n",
      "Episode 14\n",
      "Total return: 29.0\n",
      "Episode 15\n",
      "Total return: 12.0\n",
      "Episode 16\n",
      "Total return: 11.0\n",
      "Episode 17\n",
      "Total return: 46.0\n",
      "Episode 18\n",
      "Total return: 23.0\n",
      "Episode 19\n",
      "Total return: 32.0\n",
      "Episode 20\n",
      "Total return: 73.0\n",
      "Episode 21\n",
      "Total return: 47.0\n",
      "Episode 22\n",
      "Total return: 38.0\n",
      "Episode 23\n",
      "Total return: 39.0\n",
      "Episode 24\n",
      "Total return: 9.0\n",
      "Episode 25\n",
      "Total return: 13.0\n",
      "Episode 26\n",
      "Total return: 12.0\n",
      "Episode 27\n",
      "Total return: 75.0\n",
      "Episode 28\n",
      "Total return: 28.0\n",
      "Episode 29\n",
      "Total return: 30.0\n",
      "Episode 30\n",
      "Total return: 112.0\n",
      "Episode 31\n",
      "Total return: 22.0\n",
      "Episode 32\n",
      "Total return: 43.0\n",
      "Episode 33\n",
      "Total return: 17.0\n",
      "Episode 34\n",
      "Total return: 101.0\n",
      "Episode 35\n",
      "Total return: 26.0\n",
      "Episode 36\n",
      "Total return: 24.0\n",
      "Episode 37\n",
      "Total return: 29.0\n",
      "Episode 38\n",
      "Total return: 45.0\n",
      "Episode 39\n",
      "Total return: 64.0\n",
      "Episode 40\n",
      "Total return: 75.0\n",
      "Episode 41\n",
      "Total return: 30.0\n",
      "Episode 42\n",
      "Total return: 15.0\n",
      "Episode 43\n",
      "Total return: 24.0\n",
      "Episode 44\n",
      "Total return: 14.0\n",
      "Episode 45\n",
      "Total return: 20.0\n",
      "Episode 46\n",
      "Total return: 12.0\n",
      "Episode 47\n",
      "Total return: 33.0\n",
      "Episode 48\n",
      "Total return: 21.0\n",
      "Episode 49\n",
      "Total return: 45.0\n",
      "Episode 50\n",
      "Total return: 20.0\n",
      "Episode 51\n",
      "Total return: 9.0\n",
      "Episode 52\n",
      "Total return: 29.0\n",
      "Episode 53\n",
      "Total return: 20.0\n",
      "Episode 54\n",
      "Total return: 18.0\n",
      "Episode 55\n",
      "Total return: 33.0\n",
      "Episode 56\n",
      "Total return: 13.0\n",
      "Episode 57\n",
      "Total return: 14.0\n",
      "Episode 58\n",
      "Total return: 52.0\n",
      "Episode 59\n",
      "Total return: 13.0\n",
      "Episode 60\n",
      "Total return: 34.0\n",
      "Episode 61\n",
      "Total return: 18.0\n",
      "Episode 62\n",
      "Total return: 22.0\n",
      "Episode 63\n",
      "Total return: 15.0\n",
      "Episode 64\n",
      "Total return: 34.0\n",
      "Episode 65\n",
      "Total return: 19.0\n",
      "Episode 66\n",
      "Total return: 67.0\n",
      "Episode 67\n",
      "Total return: 10.0\n",
      "Episode 68\n",
      "Total return: 33.0\n",
      "Episode 69\n",
      "Total return: 44.0\n",
      "Episode 70\n",
      "Total return: 16.0\n",
      "Episode 71\n",
      "Total return: 50.0\n",
      "Episode 72\n",
      "Total return: 92.0\n",
      "Episode 73\n",
      "Total return: 42.0\n",
      "Episode 74\n",
      "Total return: 25.0\n",
      "Episode 75\n",
      "Total return: 14.0\n",
      "Episode 76\n",
      "Total return: 24.0\n",
      "Episode 77\n",
      "Total return: 44.0\n",
      "Episode 78\n",
      "Total return: 28.0\n",
      "Episode 79\n",
      "Total return: 29.0\n",
      "Episode 80\n",
      "Total return: 32.0\n",
      "Episode 81\n",
      "Total return: 31.0\n",
      "Episode 82\n",
      "Total return: 16.0\n",
      "Episode 83\n",
      "Total return: 49.0\n",
      "Episode 84\n",
      "Total return: 14.0\n",
      "Episode 85\n",
      "Total return: 107.0\n",
      "Episode 86\n",
      "Total return: 11.0\n",
      "Episode 87\n",
      "Total return: 72.0\n",
      "Episode 88\n",
      "Total return: 16.0\n",
      "Episode 89\n",
      "Total return: 24.0\n",
      "Episode 90\n",
      "Total return: 19.0\n",
      "Episode 91\n",
      "Total return: 14.0\n",
      "Episode 92\n",
      "Total return: 18.0\n",
      "Episode 93\n",
      "Total return: 68.0\n",
      "Episode 94\n",
      "Total return: 46.0\n",
      "Episode 95\n",
      "Total return: 24.0\n",
      "Episode 96\n",
      "Total return: 16.0\n",
      "Episode 97\n",
      "Total return: 24.0\n",
      "Episode 98\n",
      "Total return: 50.0\n",
      "Episode 99\n",
      "Total return: 57.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(\"Episode\", i)\n",
    "    obs = env.reset()\n",
    "    total_return = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        ind = q_map(obs)\n",
    "        if np.random.rand() > .1:\n",
    "            action = np.argmax(Q[ind])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        total_return += reward\n",
    "\n",
    "        Q[ind, action] = reward + 0.99 * np.max(Q[q_map(obs)])\n",
    "    print(\"Total return:\", total_return)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba164e4f",
   "metadata": {},
   "source": [
    "Now that we've trained a Q function we can visualize how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a07d0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "done = False\n",
    "while not done:\n",
    "    ind = q_map(obs)\n",
    "    if np.random.rand() > .1:\n",
    "        action = np.argmax(Q[ind])\n",
    "    else:\n",
    "        action = env.action_space.sample()\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "\n",
    "    Q[ind, action] = reward + 0.99 * np.max(Q[q_map(obs)])\n",
    "\n",
    "    img.set_data(env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
